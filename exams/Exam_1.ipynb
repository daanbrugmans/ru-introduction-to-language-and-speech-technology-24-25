{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272QdUl-C7w4"
      },
      "source": [
        "\n",
        "##### LET-REMA-LCEX19 Introduction to Language and Speech Technology Take-home exam\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#**Theme: Een Taal is geen Taal**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Welcome to the take-home exam of the first part of the course. The theme of this exam is **Een Taal is geen Taal**: Most people speak more than one language, yet our language technologies tend to struggle with multilingual input - especially if the language is not one of the few languages that most work in NLP is done on. The challenges and limitations of enabling human language technologies to equally support all languages in the world are plenty. How are words (and other elements) in different languages even represented in computers? What about other levels of representation, large and small? From the very basics to complex ML applications, how do Natural Language Processing (NLP) pipelines typically deal with different languages and why is it so hard to build systems that work well across multiple languages? What practices and solutions has the field come up with? What challenges can multilingual data cause in specific NLP applications, e.g. text classification or language modeling? What inequalities are build into such technologies? Feel free to pursue your personal interests within this theme. Possible directions to take this in are:\n",
        "\n",
        "- how to build a multilingual NLP pipeline that works equally well across diverse languages;\n",
        "- compare two languages and contempate differences, challenges, and linguistic issues that arise;\n",
        "- comparisons between different varieties, dialects or sociolects with NLP pipelines/applications in mind.      \n",
        "\n",
        "If you have a significantly different type of essay in mind that you want to write, please contact us via email and quickly check with us.\n",
        "\n",
        "###  Instructions\n",
        "\n",
        "This is an **individual** take-home exam. Please complete the exam on your own and write entirely in your own words.\n",
        "\n",
        "Think of this exam as an essay discussing the theme “Een Taal is geen Taal”. Your text should comparatively discuss various issues that relate to how (elements of) different human languages are represented in NLP pipelines. Your discussion should include (at least) the following type of issues:\n",
        "\n",
        "- How does character encoding work in different languages?\n",
        "- How does tokenizing work in different languages?\n",
        "- How does stemming/lemmatization work in different languages?\n",
        "- How does parsing work in different languages?\n",
        "- How does text classification work ( e.g. bag of words, Naive Bayes vs LLMs)\n",
        "- How does language modelling (e.g. ngrams, Markov assumption, (instruction-tuned) large language models)\n",
        "\n",
        "\n",
        "Write the exam in form of an Python notebook (.ipynb). The easiest way to get started is to make a copy of this very document here and start working below. The exam should contain both text cells (written in full sentences) and code cells (with pseudocode) to illustrate relevant concepts.\n",
        "\n",
        "Use pseudocode only for illustrative purposes. No data needed - you do not need to actually build a data processing pipeline! You could, for instance, use pseudo code to illustrate how a word can be tokenised in different ways or how words of different languages are encoded as unicode etc.\n",
        "\n",
        "No minimum number of code cells is specified - include as many code cells in your document as you see fit.\n",
        "\n",
        "### What is pseudocode?\n",
        "\n",
        "If you are not familiar with pseudocode, start with this [short video tutorial](https://www.youtube.com/watch?v=qfckDdsEIq8).\n",
        "Your pseudocode does not have to be of any particular format. Just writing out the steps of your pipeline in plain English (like shown in the video tutorial) will suffice. You can also write in actual code, e.g. Python, but you will not get extra credits for doing so.\n",
        "\n",
        "### Length\n",
        "\n",
        "Aim for a submission of around 2500 words (excluding this existing instruction text, the bibliography, and your pseudocode cells). Diverging from this aim by more than 20% will impact the grade.   \n",
        "\n",
        "The easiest way to check the length of your document is to copy the text into a word processor or to download the file as Python code (.py) and open that file in Microsoft Word to count the words.\n",
        "\n",
        "\n",
        "### Exam weight\n",
        "This exam is 50% of the overall course grade.\n",
        "\n",
        "### Grading\n",
        "\n",
        "The exam will be graded for:\n",
        "\n",
        "- **Completeness** [primary]: Does the submission cover all aspects of preprocessing and NLP applications that were covered in the course? Please stick to the theme \"From words to numbers\" but cover all relevant linguistic and technical problems, challenges, and solutions of how various elements of written natural human language are represented and used in language technology.\n",
        "\n",
        "- **Depth of description** [secondary]: Are all concepts and steps explained clearly, thoroughly and concisely? Are all steps of a typical language processing pipelines described in sufficient detail? Is (pseudo)code used well for illustration purposes?\n",
        "\n",
        "- **Presentation** [tertiary]: Is the submission well organized, formatted, and professionally presented using both text and code cells? Your submission should be readable like an essay. It should not only entirely be written in full sentences (except the pseudocode cells), but quality of writing matters: write in a clear, academic, and succinct style. Include references to the course text book (link [link text](https://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf)) where relevant and include a bibliography. References to literature other than to (Jurafsky and Martin 2023, p.xx) are encouraged but not required.\n",
        "\n",
        "The minimum grade to pass the exam is 5.5.\n",
        "\n",
        "The use of text generators (e.g. ChatGPT) is **not allowed** and is treated as a form of plagiarism, we will test each submission for that.\n",
        "\n",
        "### Submission\n",
        "\n",
        "Submit the exam via Brightspace as an iPython notebook (.ipynb) file **by the deadline**.\n",
        "\n",
        "\n",
        "Good luck!\n",
        "\n",
        "Andreas Liesenfeld and Cristian Tejedor-García"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfxitI1BlkqM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Your name: **Daan Brugmans**\n",
        "\n",
        "Student number: **S1080742**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9-pDrE9-_bh"
      },
      "source": [
        "# Introduction: state of the art, challenges and opportunities\n",
        "\n",
        "The concept of \"Eén Taal is Géén Taal\" (\"One Language is No Language\") is currently a hot topic within the field of NLP. With English as the modern professional *lingua franca*, it may come as no surprise that state-of-the-art language technology research is typically performed in and in service of English. The vast wealth of English language resources offers researchers plenty of data to train their models. English is what is (generally) considered a ***high-resource language***: a language with many resources from which plenty of data can be extracted for whatever language technology purpose. English may be considered one of the \"lucky few\" in the high-resource language group, as the ***low-resource language*** group, for which only a relatively small, limited number of resources exist, encompass most of the languages spoken and written. The low-resource language group not only emcompasses many minority languages that are recognized by governments, such as Papiamento and Frisian ([*Erkende talen in Nederland*, 2024](https://www.rijksoverheid.nl/onderwerpen/erkende-talen/erkende-talen-in-nl)), but also languages that aren't officially recognized, such as Brabantian and Zeelandic, local dialects, such as Huissens ([*Historische kring Huessen - Huussese Taol, 2024*](https://www.huessen.nl/over-huissen/dialect)), and even constructed languages, such as Esperanto. \n",
        "\n",
        "The current state-of-the-art in NLP is mostly based on high-resource languages, which is likely due to the deep learning models that underpin state-of-the-art technologies, which require vast amounts of data in order to be trained properly. Such models cannot be trained from scratch on low-resource languages, as the data that facilitates state-of-the-art models simply does not exist for those languages. As a consequence, most low-resource languages cannot be processed by state-of-the-art models. This is a major reason why multilingual NLP is such a hot topic: most languages are not even supported by modern tools yet, and the fact that those languages lack a wealth of data that can be used to implement such support is a major hurdle in realizing multilingual NLP systems.\n",
        "\n",
        "Within research on multilingual language models, one potential (partial) solution to this problem is to use existing language models trained on high-resource languages, and apply their knowledge on low-resource languages ([*Joshi. et al., 2024, Fine Tuning LLMs for Low Resource Languages*](https://doi.org/10.1109/icipcn63822.2024.00090)). LLMs pretrained on high-resource languages could be finetuned to low-resource languages. The idea is that the LLM acquires core language skills and learns universal language properties while pretraining on high-resource language(s), and by then finetuning it on low-resource languages, the expectation is that the \"general language skills\" it has learned can be carried over onto the low-resource languages, for which it then only has to learn language-specific properties such as syntax and vocabulary. Ideally, the expectation that the finetuning LLM only has to learn the low-resource language itself, without improving its general language skills, means that it may need (much) less data to achieve state-of-the-art language modelling and generation for the low-resource language. In practice, that is easier said than done.\n",
        "\n",
        "Of course, this only describes one potential solution for building multilingual language modelling systems. But a multilingual NLP pipeline has many other problems to consider as well. I will discuss some of these problems in the rest of this essay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80P5xLIx_xxq"
      },
      "source": [
        "# Elements of a maximally multilingual NLP pipeline\n",
        "\n",
        "In order to produce an NLP pipeline that is maximally multilingual, the key idea underlying the design of the pipeline should be the sheer variety of language. A maximally multilingual pipeline must not only be capable of accepting language input of as many varying representations as possible, but it must also be able to process and normalize all language input according to the language's syntax and semantics; normalizing language data in a way that does not work for that language results in garbage, and garbage in is garbage out. The downstream tasks that use the maximally multilingual pipeline should, preferably, be equally multilingual as it, and so the models underpinning the downstream tasks must be capable of handling as many languages as possible. Succinctly put: a maximally multilingual NLP pipeline must be *maximally flexible* in its language input.\n",
        "\n",
        "I will explore some elements from the inexhaustible list of qualities that make an NLP pipeline maximally multilingual. I divide this exploration in twain: one section about the handling, processing, and normalizing of maximally multilingual text data (\"Preprocessing\"), and the downstream tasks that make use of the maximally multilingual NLP pipeline (\"NLP applications\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcOoJlYuC786"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Any text input is encoded by ***characters***. The *de facto* standard for character encoding is the Unicode Standard, and is maintained by the Unicode Consortium. A maximally multilingual pipeline should use this encoding standard, so that it can support as many character encodings as possible.\n",
        "\n",
        "For most scripts, character encoding is relatively straightforward. In alphabets, such as the Latin and Cyrillic alphabets, both consonants and vowels get their own unique glyph, which can all get their own unique encoding. In Abjads, such as the Arabic and Hebrew scripts, only the consonants of words are written, and since every consonant also gets a unique glyph, they can be encoded relatively straightforwardly too. Syllabaries, such as the Japanese hiragana and katakana scripts and the Cherokee script, have a glyph for every syllable that is used in the language. Generally speaking, languages that use syllabaries as their script have simple syllable structures, such as [CV] (\"Consonant + Vowel\"), limiting the number of syllables, and thus glyphs, that exist in the script. Syllabary glyphs can thus also be relatively straightforwardly encoded. In logographies, such as the Chinese script or the related Japanese kanji script, a glyph represents a semantic component of the language. Since language is so expressive and could represent a practically inexhaustible number of semantics, logographies tend to be very large; knowing a few thousand unique characters with their meaning is considered basic when writing kanji, for example. Because of this, although encoding logographies is straightforward, it is also very costly, as many thousands of characters must all get their own unique encoding.\n",
        "\n",
        "Until now, character encoding seems to be relatively straightforward: each glyph used in a script can be directly mapped to an encoding, whether that glyph represents a consonant, vowel, syllable, or semantic component. However, when encountering and processing input from abugidas, we run into a new issue. Abugidas are scripts where each glyph represents both a consonant *and* a vowel, just like a syllabary. However, in an abugida, the consonant is taken as the root of the glyph, and the vowel is appended to it, similar to a diacritic. Examples of abugidas are Devanagari and Ge'ez. As an example of how abugida glyphs are constructured, the following image by [*Saurmandal (2023)*](https://commons.wikimedia.org/wiki/File:Devanagari_matras.svg) displays varying Devanagari glyphs with the appended vowel markings highlighted on the consonant root of the glyph.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/d/d3/Devanagari_matras.svg)\n",
        "\n",
        "If we want to encode and process Devanagari text input, it would be straightforward to encode all possible consonant-vowel combinations separately, but this would also be very resource inefficient. Instead, we could take an approach where we encode the consonants and vowels separately, but *render* them as one glyph downstream. The latter is the approach taken by the Unicode Consortium ([*(Devanagari, 2024)*](https://unicode.org/charts/PDF/U0900.pdf)). This efficient encoding also has consequences for our pipeline and downstream tasks, as our maximally multilingual pipeline, and the (deep learning) models that use it, must be capable of recognizing that in abugida-based text input, a consonant encoding followed by a vowel encoding should be processed/interpreted as if they were a singular glyph.\n",
        "\n",
        "With encoding and scripts clear, we can take a look at tokenization in our pipeline. When tokenizing maximally multilingual input, we must consider what is defined as a *token*, and how that definition is bound to the script used by the language data. In alphabets, tokens are most often individual words or morphemes, but can also be *multiword units*, where one token consists of multiple words. Even then, we are assuming that a token should be seperated from another token by a space, which may not be the case in non-alphabetic scripts. The Chinese and Japanese scripts, being lographies and syllabaries, for example, are not written with spacing between tokens, so determining what a \"token\" is in Mandarin of Japanse language input cannot be done on the basis of spacing. A solution, then, comes from using the BPE algorithm. Because the BPE algorithm learns tokens on the basis of connecting the most frequently adjoined characters in an input text, it can build a collection of tokens for any script. We can then use this collection to tokenize text across scripts. This should solve the issue of multiword/multicharacter units, and work independently of the script used. Thus, for a maximally multilingual pipeline, we should use a BPE tokenization algorithm when tokenizing words. Should we want to tokenize sentences as well, then we must be aware of languages such as Thai, which do not use end-of-sentence markers at all, complicating sentence tokenization efforts.\n",
        "\n",
        "When implementing stemming or lemmatization, we must think about what a \"stem\"/\"lemma\" and \"inflection\" *really* mean for a specific language. In most alphabetic languages, for example, a stem is most often a full morpheme that never changes, and an inflection is introduced by adding a prefix or suffix. However, in a language like Arabic, the \"root\" of a word is considered something else entirely: the Arabic \"root\" of a word is a set of multiple, often three, consonants, which form the general meaning of the word (e.g. \"k-t-b\" for \"write\"). The root is then \"inflected\" by inserting, prepending, and/or appending other vowels or consonants (e.g. \"kataba\" for \"he wrote\"). By the inflections, the root can serve as a (conjugated) verb or even a noun. Since Arabic looks at the root (stem) of a word so differently than most alphabetic languages do, should this be implemented into the maximally multilingual pipeline? I would argue in favor: if stemming units in the Arabic abjad is fundamentally different from stemming units in the Latin alphabet, then we should use a fundamentally different stemming algorithm as to best reflect Arabic's linguistic properties. A mismatch between stemming algorithm and language results in preprocessed garbage, and garbage in is garbage out. Unsurprisingly, Arabic stemming algorithms already exist for this reason, having been developed since at least 1999 *(Khoja and Garside)*.\n",
        "\n",
        "We will end our discussion of preprocessing language data maximally multilingually by considering syntactic and semantic parsing. Many aspects of syntax vary between languages; a basic example is the word order of the subject, object, and verb of a sentence, a syntactic property that influences the syntactic trees we build for a language and one that can be used as a feature for a model in a downstream task. Case markings are a different way of indicating the subject and objects in some languages, which allow for free word order and should also be accounted for when parsing syntax.\n",
        "\n",
        "When parsing semantics, especially for downstream tasks, one semantic unit can be represented using very different expressions, even across very closely related languages: English \"girl\", Dutch \"meisje\", Frisian \"famke\", and Huissens \"dèrnje\" all mean the same thing, yet look very different. How do we deal with this interlingual synonymy? One popular solution is the concept of the ***semantic space***. A semantic space is a highly dimensional vector space, where every dimension represents a semantic concept, and moving along an axis shifts a vector's semantics. When trained on language data, deep learning models learn to develop such semantic spaces internally. I suggest that, in a maximally multilingual pipeline, a downstream (L)LM, having developed a singular internal semantic space, could handle input from many languages by processing all language input within the same semantic space. This way, a model can understand that \"girl\", \"meisje\", \"famke\", and \"'dèrnje\" are semantically identical, for example. Then, when prompted to generate text, it could do so by sampling from the multilingual semantic space and expressing those semantics in the desired language. I propose that this could be a reason why the LLMs from the introduction, pretrained on high-resource languages, are capable of finetuning on low-resource languages: the LLMs learn to contextualize a new language in their existing semantic space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 1: Processing Abugidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "coN_j2nNHjA_"
      },
      "outputs": [],
      "source": [
        "raw_text = \"\"\"हे हमारे स्वर्गबासी पिता,\n",
        "तेरा नाम पवित्र माना जाए,\n",
        "तेरा राज्य आए,\n",
        "तेरी इच्छा जैसे स्वर्ग मे पूरी होती है,\n",
        "वैसे ही पृथ्वी पर पूरी हो,\n",
        "हमारे रोज़ की रोटी आज हमें दे,\n",
        "और जैसे हम आपने रिणियों को क्षमा कर्ते हैं तैसे हमारी रिणों को क्षमा कर,\n",
        "और हमें परीक्षा में मत डाल,\n",
        "परन्तु दुष्ट से बचा।\n",
        "[क्योंकि राज्य और पराक्रम और महिमा सदा तेरे हैं। आमीन\"\"\"\n",
        "\n",
        "if raw_text.script == \"Devanagari\":\n",
        "    split_devanagari_text = split_devanagari_consonants_from_vowels(raw_text)\n",
        "\n",
        "    learned_tokens = BPE(split_devanagari_text)\n",
        "    learned_tokens.save(\"/path\")\n",
        "\n",
        "    tokenized_text = tokenize(raw_text, learned_tokens)\n",
        "\n",
        "    # Further preprocessing...\n",
        "\n",
        "\n",
        "# Downstream\n",
        "model = PretrainedLargeLanguageModel()\n",
        "model.finetune = True\n",
        "\n",
        "for tokenized_unit in tokenized_text:\n",
        "    if tokenized_unit.script == \"Devanagari\":\n",
        "        for consonant, vowel in tokenized_unit:\n",
        "            glyph = concat_devanagari_to_glyph(consonant, vowel)\n",
        "            model.predict_next_token(glyph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 2: Language-Sensitive Unit Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_text = \"\"\"أَبَانَا الذِي فِي السَّمَاوَاتِ،\n",
        "لِيَتَقَدَّسَ اسْمُكَ\n",
        "لِيَأْتِ مَلَكُوتُكَ\n",
        "لِتَكُنْ مَشِيئَتُكَ فِي الأَرْضِ كَمَا السَّمَاءِ\n",
        "اعْطِنَا خُبْزَنَا اليَوْمِيَّ\n",
        "اعْفِنَا فِي مِمَّا عَلَيْنَا فَقَدْ أَعْفَيْنَا نَحْنُ أيَضاً مَنْ\n",
        "لَنَا عَلَيْهِ\n",
        "وَلاَ تُدْخِلْنَا فِي تَجْرِبَةٍ\n",
        "لَكِنْ نَجِّنَا مِنَ الشِّرِّيرِ لأَنَّ لَكَ الْمُلْكَ وَالْقُوَّةَ وَالْمَجْدَ إِلَى الأَبَدِ\n",
        "آمِين\"\"\"\n",
        "\n",
        "if raw_text.language == \"English\":\n",
        "    stemmed_text = porter_stemmer(raw_text)\n",
        "elif raw_text.language == \"Arabic\":\n",
        "    stemmed_text = khoja_stemmer(raw_text)\n",
        "# Etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpuPEbpDGdZ4"
      },
      "source": [
        "# NLP applications\n",
        "\n",
        "For this essay, I limit discussion of applications to the tasks of text classification and language modelling.\n",
        "\n",
        "Since the contents of a text are almost always what determine its classification, text classification tasks are inherently subject to the language(s) present in the text and its characteristics. A maximally multilingual text classification system must either be capable of indiscriminately handling any combination of languages that could potentially be present in a text, or have separate models for every potential language, and then apply the right one. The latter would require language identification techniques to be used in order to determine which model should be used. \n",
        "\n",
        "Preferably, we would have a singular system or model that is capable of handling any and all languages. But how can we build a system capable of such feats? One solution could be to apply machine translation to the input text: we have a system or model that works on a single language, and when language input from a different language is detected, it is first translated into the language understood by our model/system, and then processed by it. This approach is unfortunately not ideal: not only must we take the effort to translate, but translated text often does not reflect the original text's syntactic and semantic structures well, especially when we translate between distantly related languages. A promising alternative is the use of a semantic space, since semantic spaces can potentially capture semantics of units across many languages within the same space. A system with a semantic space, such as a deep learning model, could be capable of performing the same classification task on texts of many languages by learning to use a singular semantic space when processing multilingual input.\n",
        "\n",
        "For language modelling tasks, a system must not only be capable of accepting and processing multilingual input, but also capable of producing multilingual output. As I have already suggested, I propose that systems that utilize a semantic space should be capable of contextualizing language input across many languages, and could sample from the semantic space when generating text, and express those sampled semantics in the language desired by the end user. This would allow modern LLMs to converse in many languages. One last issue to raise, then, is whether LLMs with maximally multilingual semantic spaces are capable of ***code-switching***, the act of changing language during conversation. If LLMs can express themselves in multiple languages, can they do so within the same prompt? Research by [Zhang et al. (*2023*)](https://aclanthology.org/2023.emnlp-main.774/) seems to imply not, or at least not to the extend that models finetuned for code-switching tasks are capable of. It seems that interoperability between languages is not (yet) a solved language modelling task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 3: Developing and Using a Multilingual Semantic Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LydnauQ3l8l9"
      },
      "outputs": [],
      "source": [
        "high_resource_language_texts = {\n",
        "    \"En\": \"\"\"Our Father in heaven,\n",
        "        hallowed be your name,\n",
        "        your kingdom come,\n",
        "        your will be done,\n",
        "        on earth as in heaven.\n",
        "        Give us today our daily bread.\n",
        "        Forgive us our sins\n",
        "        as we forgive those who sin against us.\n",
        "        Lead us not into temptation\n",
        "        but deliver us from evil.\n",
        "        For the kingdom, the power,\n",
        "        and the glory are yours\n",
        "        now and for ever.\n",
        "        Amen.\n",
        "        \"\"\",\n",
        "    \"Es\": \"\"\"Padre nuestro,\n",
        "        que estàs en el cielo,\n",
        "        santificado sea tu Nombre;\n",
        "        venga a nosotros tu reino;\n",
        "        hágase tu voluntad\n",
        "        en la tierra como en el cielo.\n",
        "        Danos hoy nuestro pan de cada día;\n",
        "        perdona nuestras ofensas,\n",
        "        como también nosotros perdonamos\n",
        "        a los que nos ofenden;\n",
        "        no nos dejes caer en la tentación,\n",
        "        y líbranos del mal.\n",
        "        Amén.\"\"\",\n",
        "    \"Jp\": \"\"\"天におられる私たちの父よ\n",
        "        み名が聖とされますように\n",
        "        み国がきますように\n",
        "        みこころが天に行われるとおり\n",
        "        地にも行われますように\n",
        "        私たちの日ごとの糧を今日もお与えください\n",
        "        私たちの罪をおゆるしください\n",
        "        私たちも人をゆるします\n",
        "        私たちを誘惑におちいらせず、悪からお救いください\n",
        "        アーメン\"\"\"\n",
        "}\n",
        "\n",
        "low_resource_language_texts = {\n",
        "    \"Hui\": \"Van wie bun gèj d'r één?\",\n",
        "    \"Gae\": \"Ciamar a tha sibh?\",\n",
        "    \"Man\": \"ᠰᡳᠨᡳ ᡤᡝᠪᡠ ᠠᡳ ᠰᡝᠮᠪᡳ᠉ ?\"\n",
        "}\n",
        "\n",
        "\n",
        "language_model = LanguageModel()\n",
        "\n",
        "for language_text in high_resource_language_texts:\n",
        "    language_model.pretrain(language_text) # Developing semantic space\n",
        "language_model.save(\"/path/pretrained.model\")\n",
        "\n",
        "for language_text in low_resource_language_texts:\n",
        "    language_model.finetune(language_text) # Updating semantic space\n",
        "language_model.save(\"/path/finetuned.model\")\n",
        "\n",
        "\n",
        "english_answer = model.sample(\"What is your name?\", output_language=\"En\")\n",
        "spanish_answer = model.sample(\"What is your name?\", output_language=\"Es\")\n",
        "huissens_answer = model.sample(\"¿Cómo te llamas?\", output_language=\"Hui\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHWLMYS9_XwQ"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "As I have hopefully demonstrated, the construction of a maximally multilingual NLP pipeline is made very difficult by the sheer variety of human language; even though I touched on only a fraction of all aspects of language and natural language processing, it is already clear that variety in scripts, vocabulary, and even availability of resources complicate the development of a maximally multilingual pipeline. It should be clear, then, that a maximally multilingual NLP pipeline is also maximally flexible in what language data it can accept, how it can process language data according to the language's properties, and how the data is fed to and used in downstream tasks. Finally, it should hopefully also be clear that the issue of developing a maximally multilingual pipeline is far from a solved problem, with many avenues of research still laying open."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bibliography\n",
        "\n",
        "Devanagari: 2024. https://unicode.org/charts/PDF/U0900.pdf. \n",
        "\n",
        "Erkende talen in Nederland: 2024. https://www.rijksoverheid.nl/onderwerpen/erkende-talen/erkende-talen-in-nl\n",
        "\n",
        "Historische kring Huessen - Huussese Taol: https://www.huessen.nl/over-huissen/dialect. \n",
        "\n",
        "Joshi, S. et al. 2024. Fine Tuning LLMs for Low Resource Languages. 5th International Conference on Image Processing and Capsule Networks (ICIPCN). (Jul. 2024), 511–519. DOI:https://doi.org/10.1109/icipcn63822.2024.00090. \n",
        "\n",
        "Khoja and Garside 1999. Stemming Arabic Text. Lancaster, UK, Computing Department, Lancaster University. (1999). \n",
        "\n",
        "Saurmandal 2023. Devanagari matras. \n",
        "\n",
        "Zhang, R. et al. 2023. Multilingual Large Language Models Are Not (Yet) Code-Switchers. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. (Dec. 2023). DOI:https://doi.org/10.18653/v1/2023.emnlp-main.774."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
